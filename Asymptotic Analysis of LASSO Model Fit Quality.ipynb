{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71297ba4",
   "metadata": {},
   "source": [
    "## Asymptotic Analysis of LASSO Model Fit Quality\n",
    "\n",
    "The LASSO regression model fits effective resistance $R_{\\text{eff}}(u, v)$ as a function of geometric features. The key question we want to investigate is: **how does the quality of the model fit behave in the thermodynamic limit as $n \\to \\infty$?**\n",
    "\n",
    "### Setup\n",
    "\n",
    "We study fit quality (measured by out-of-sample $R^2$) across a grid of $(n, k)$ values, where:\n",
    "\n",
    "- $n \\in [256, 512, 1024, 2048, 4096, 8192]$ is the number of nodes\n",
    "- $k \\in [5, 6, 7, 8, 9]$ is the **expected mean degree**, which controls the connection radius via $r = \\sqrt{k / ((n-1)\\pi)}$\n",
    "\n",
    "The model is trained by pooling samples from 100 independently generated RGGs (seeds 0-99) and evaluated on 20 held-out graphs (seeds 100-119), ensuring the $R^2$ score reflects out-of-sample generalisation rather than in-sample memorisation.\n",
    "\n",
    "### The Fixed Mean Degree Regime\n",
    "\n",
    "In the **supercritical regime** used here, $k$ is held fixed as $n$ grows. Since the radius $r \\propto n^{-1/2}$ shrinks as $n$ increases, each node's neighbourhood becomes a smaller and smaller fraction of the torus. Locally, the graph looks increasingly like an infinite planar random geometric graph.\n",
    "\n",
    "This raises a natural question: does our fixed geometric feature set remain a good predictor of $R_{\\text{eff}}$ in this super critical regime limit, or does the fit deteriorate as the graph grows large and the effective resistance landscape becomes harder to capture with low-order terms?\n",
    "\n",
    "We expect the answer to depend on $k$:\n",
    "\n",
    "The reference curve $\\ln(n) = k$ (equivalently $n = e^k$) marks the boundary of the **connected regime**: values of n above this curve make the supercritical radius no longer sufficient to guarantee connectivity with high probability. Points above this line should be interpreted with caution, as disconnected graphs are resolved by restricting to the largest connected component.\n",
    "\n",
    "### What We Are Looking For\n",
    "\n",
    "The heatmap produced below allows us to visually assess:\n",
    "\n",
    "1. Whether $R^2$ is broadly stable across $n$ for a fixed $k$ (suggesting the feature set captures the right asymptotic structure), or whether it decays systematically.\n",
    "2. Whether higher $k$ consistently yields better fits, and whether this effect strengthens or weakens as $n$ grows.\n",
    "3. Whether there is a phase transition in fit quality near the $\\ln(n) = k$ boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be859f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] Running n=256, k=5 ...  R² = 0.2311\n",
      "[2/30] Running n=256, k=6 ...  R² = 0.4232\n",
      "[3/30] Running n=256, k=7 ...  R² = 0.6047\n",
      "[4/30] Running n=256, k=8 ...  "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from RGG_Library import RGGBuilder\n",
    "\n",
    "space_ = \"torus\"\n",
    "use_angles = True\n",
    "perturb_bool = False\n",
    "\n",
    "# ---------------------------\n",
    "# GRID PARAMETERS\n",
    "# ---------------------------\n",
    "n_values = [256, 512, 1024, 2048, 4096, 8192]\n",
    "k_values = [5, 6, 7, 8, 9]\n",
    "nsamples = 1000       # samples per graph\n",
    "n_train_graphs = 100    # graphs to pool for training\n",
    "n_test_graphs  = 20    # graphs to pool for testing\n",
    "base_seed      = 0    # train seeds: base_seed + 0..4, test seeds: base_seed + 5..7\n",
    "\n",
    "# ---------------------------\n",
    "# HELPER: build graph & extract features\n",
    "# ---------------------------\n",
    "def build_features(n, k, nsamples, seed):\n",
    "    \"\"\"\n",
    "    Build one RGG and return (X, y). Returns (None, None) on failure.\n",
    "    \"\"\"\n",
    "    builder = RGGBuilder(\n",
    "        n=n, k=k, connectivity_regime=\"sc\",\n",
    "        space=space_, order=4, perturb=perturb_bool, seed=seed\n",
    "    )\n",
    "    G = builder.build()\n",
    "\n",
    "    if not nx.is_connected(G):\n",
    "        components = list(nx.connected_components(G))\n",
    "        if not components:\n",
    "            return None, None\n",
    "        Gsub = G.subgraph(max(components, key=len)).copy()\n",
    "    else:\n",
    "        Gsub = G\n",
    "\n",
    "    Gsub = nx.convert_node_labels_to_integers(Gsub, ordering=\"sorted\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if use_angles:\n",
    "        res, degs, dists, pairs, angles = RGGBuilder.sample_commute_times_even_distance_w_angles(\n",
    "            Gsub, nsamples=nsamples, n_bins=20, seed=seed,\n",
    "            min_dist=builder.radius, max_dist=2\n",
    "        )\n",
    "    else:\n",
    "        res, degs, dists, pairs = RGGBuilder.sample_commute_times_even_distance(\n",
    "            Gsub, nsamples=nsamples, n_bins=20, seed=seed,\n",
    "            min_dist=builder.radius, max_dist=2\n",
    "        )\n",
    "\n",
    "    if len(res) < 10:\n",
    "        return None, None\n",
    "\n",
    "    safe_dists = dists.copy()\n",
    "    safe_dists[safe_dists == 0] = 1e-9\n",
    "    current_angles = angles if use_angles else np.zeros_like(dists)\n",
    "\n",
    "    X = np.column_stack([\n",
    "        dists**2,\n",
    "        np.log(safe_dists),\n",
    "        dists**4 * np.cos(4 * current_angles),\n",
    "        dists**8 * np.cos(8 * current_angles),\n",
    "        degs,\n",
    "    ])\n",
    "    y = np.array(res)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CORE FUNCTION\n",
    "# ---------------------------\n",
    "def compute_r2(n, k, nsamples=1000, base_seed=0):\n",
    "    \"\"\"\n",
    "    Train LASSO on n_train_graphs pooled graphs, test on n_test_graphs pooled graphs.\n",
    "    Returns out-of-sample R². Returns NaN on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- TRAINING: pool data from n_train_graphs graphs ---\n",
    "        X_train_parts, y_train_parts = [], []\n",
    "        for i in range(n_train_graphs):\n",
    "            X, y = build_features(n, k, nsamples, seed=base_seed + i)\n",
    "            if X is not None:\n",
    "                X_train_parts.append(X)\n",
    "                y_train_parts.append(y)\n",
    "\n",
    "        if len(X_train_parts) == 0:\n",
    "            return np.nan\n",
    "\n",
    "        X_train = np.vstack(X_train_parts)\n",
    "        y_train = np.concatenate(y_train_parts)\n",
    "\n",
    "        # --- FIT LASSO ---\n",
    "        model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            Lasso(alpha=1e-6, random_state=0, max_iter=50000)\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        lasso  = model.named_steps['lasso']\n",
    "        scaler = model.named_steps['standardscaler']\n",
    "        real_coefs     = lasso.coef_ / scaler.scale_\n",
    "        real_intercept = lasso.intercept_ - np.sum(real_coefs * scaler.mean_)\n",
    "\n",
    "        # --- TESTING: pool data from n_test_graphs new graphs ---\n",
    "        X_test_parts, y_test_parts = [], []\n",
    "        for i in range(n_test_graphs):\n",
    "            # Use seeds that don't overlap with training seeds\n",
    "            X, y = build_features(n, k, nsamples, seed=base_seed + n_train_graphs + i)\n",
    "            if X is not None:\n",
    "                X_test_parts.append(X)\n",
    "                y_test_parts.append(y)\n",
    "\n",
    "        if len(X_test_parts) == 0:\n",
    "            return np.nan\n",
    "\n",
    "        X_test = np.vstack(X_test_parts)\n",
    "        y_test = np.concatenate(y_test_parts)\n",
    "\n",
    "        # --- OUT-OF-SAMPLE R² ---\n",
    "        y_pred  = X_test @ real_coefs + real_intercept\n",
    "        ss_res  = np.sum((y_test - y_pred) ** 2)\n",
    "        ss_tot  = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "        r2      = 1 - ss_res / ss_tot\n",
    "\n",
    "        return float(r2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] n={n}, k={k} failed: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# SWEEP OVER GRID\n",
    "# ---------------------------\n",
    "R2_grid = np.full((len(n_values), len(k_values)), np.nan)\n",
    "\n",
    "total = len(n_values) * len(k_values)\n",
    "done  = 0\n",
    "\n",
    "for i, n in enumerate(n_values):\n",
    "    for j, k in enumerate(k_values):\n",
    "        done += 1\n",
    "        print(f\"[{done}/{total}] Running n={n}, k={k} ...\", end=\"  \")\n",
    "        r2 = compute_r2(n, k, nsamples=nsamples, base_seed=base_seed)\n",
    "        R2_grid[i, j] = r2\n",
    "        print(f\"R² = {r2:.4f}\" if not np.isnan(r2) else \"R² = NaN\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# SCATTER PLOT\n",
    "# ---------------------------\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "# Flatten grid into lists of (n, k, r2) points\n",
    "ns, ks, r2s = [], [], []\n",
    "for i, n in enumerate(n_values):\n",
    "    for j, k in enumerate(k_values):\n",
    "        val = R2_grid[i, j]\n",
    "        ns.append(n)\n",
    "        ks.append(k)\n",
    "        r2s.append(val)\n",
    "\n",
    "ns   = np.array(ns)\n",
    "ks   = np.array(ks)\n",
    "r2s  = np.array(r2s)\n",
    "\n",
    "# Separate valid and NaN points\n",
    "valid = ~np.isnan(r2s)\n",
    "\n",
    "cmap = plt.cm.RdYlGn\n",
    "norm = plt.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "sc = ax.scatter(\n",
    "    ks[valid], ns[valid],\n",
    "    c=r2s[valid],\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    s=400,\n",
    "    edgecolors='k',\n",
    "    linewidths=0.6,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "# Plot NaN points as grey X markers\n",
    "if np.any(~valid):\n",
    "    ax.scatter(\n",
    "        ks[~valid], ns[~valid],\n",
    "        c='lightgrey', marker='X', s=200,\n",
    "        edgecolors='k', linewidths=0.6,\n",
    "        label='NaN', zorder=3\n",
    "    )\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "# Annotate each point with its R² value\n",
    "for n, k, r2 in zip(ns, ks, r2s):\n",
    "    if not np.isnan(r2):\n",
    "        text_color = \"black\" if 0.2 < r2 else \"white\"\n",
    "        ax.annotate(\n",
    "            f\"{r2:.3f}\", (k, n),\n",
    "            ha='center', va='center',\n",
    "            fontsize=7.5, fontweight='bold', color=text_color,\n",
    "            zorder=4\n",
    "        )\n",
    "\n",
    "# Curve: ln(n) = k  →  n = e^k\n",
    "k_curve = np.linspace(min(k_values), max(k_values), 300)\n",
    "n_curve = np.exp(k_curve)\n",
    "ax.plot(k_curve, n_curve, 'b--', linewidth=1.8, label=r'$\\ln(n) = k$', zorder=2)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "plt.colorbar(sc, ax=ax, label=\"Out-of-Sample R²\", fraction=0.03, pad=0.02)\n",
    "\n",
    "ax.set_xlabel(\"Mean Degree  k\", fontsize=13)\n",
    "ax.set_ylabel(\"Number of Nodes  n\", fontsize=13)\n",
    "ax.set_title(\n",
    "    f\"LASSO Out-of-Sample R²  across  (n, k)  regimes\\n\"\n",
    "    f\"(Train: {n_train_graphs} graphs × {nsamples} pts  |  Test: {n_test_graphs} graphs × {nsamples} pts)\",\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "ax.set_xticks(k_values)\n",
    "ax.set_yticks(n_values)\n",
    "ax.yaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, linestyle='--', alpha=0.4, zorder=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
