{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71297ba4",
   "metadata": {},
   "source": [
    "## Asymptotic Analysis of LASSO Model Fit Quality\n",
    "\n",
    "The LASSO regression model fits effective resistance $R_{\\text{eff}}(u, v)$ as a function of geometric features. The key question we want to investigate is: **how does the quality of the model fit behave in the thermodynamic limit as $n \\to \\infty$?**\n",
    "\n",
    "### Setup\n",
    "\n",
    "We study fit quality (measured by out-of-sample $R^2$) across a grid of $(n, k)$ values, where:\n",
    "\n",
    "- $n \\in [256, 512, 1024, 2048, 4096]$ is the number of nodes\n",
    "- $k \\in [5, 6, 7, 8, 9]$ is the **expected mean degree**, which controls the connection radius via $r = \\sqrt{k / ((n-1)\\pi)}$\n",
    "\n",
    "The model is trained by pooling samples from independently generated RGGs and evaluated on held-out graphs, ensuring the $R^2$ score reflects out-of-sample generalisation rather than in-sample memorisation.\n",
    "\n",
    "### The Fixed Mean Degree Regime\n",
    "\n",
    "In the **supercritical regime** used here, $k$ is held fixed as $n$ grows. Since the radius $r \\propto n^{-1/2}$ shrinks as $n$ increases, each node's neighbourhood becomes a smaller and smaller fraction of the torus. Locally, the graph looks increasingly like an infinite planar random geometric graph.\n",
    "\n",
    "This raises a natural question: does our fixed geometric feature set remain a good predictor of $R_{\\text{eff}}$ in this super critical regime limit, or does the fit deteriorate as the graph grows large and the effective resistance landscape becomes harder to capture with low-order terms?\n",
    "\n",
    "We expect the answer to depend on $k$:\n",
    "\n",
    "The reference curve $\\ln(n) = k$ marks the boundary of the **connected regime**: values of n above this curve make the supercritical radius no longer sufficient to guarantee connectivity almost surely. Points beyond this line should be interpreted with caution, as disconnected graphs are resolved by restricting to the largest connected component.\n",
    "\n",
    "### What We Are Looking For\n",
    "\n",
    "The plot produced below allows us to visually assess:\n",
    "\n",
    "1. Whether $R^2$ is broadly stable across $n$ for a fixed $k$ (suggesting the feature set captures the right asymptotic structure), or whether it decays systematically.\n",
    "2. Whether higher $k$ consistently yields better fits, and whether this effect strengthens or weakens as $n$ grows.\n",
    "3. Whether there is a phase transition in fit quality near the $\\ln(n) = k$ boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be859f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from RGG_Library import RGGBuilder\n",
    "import pandas as pd\n",
    "\n",
    "SPACE = \"torus\"\n",
    "USE_ANGLES = True\n",
    "PERTURB = False\n",
    "\n",
    "# ---------------------------\n",
    "# GRID PARAMETERS\n",
    "# ---------------------------\n",
    "N_VALUES            = [512, 1024, 2048, 4096, 8192]\n",
    "K_VALUES            = [5, 6, 7, 8, 10, 12, 16, 20]\n",
    "NSAMPLES            = 1000\n",
    "N_TRAIN_GRAPHS      = 30\n",
    "N_TEST_GRAPHS       = 20\n",
    "BASE_SEED           = 0\n",
    "\n",
    "# ---------------------------\n",
    "# HELPER: build graph & extract features\n",
    "# ---------------------------\n",
    "def build_features(n, k, nsamples, seed):\n",
    "    \"\"\"\n",
    "    Build one RGG and return (X, y). Returns (None, None) on failure.\n",
    "    \"\"\"\n",
    "    builder = RGGBuilder(\n",
    "        n=n, k=k, connectivity_regime=\"sc\",\n",
    "        space=SPACE, order=4, perturb=PERTURB, seed=seed\n",
    "    )\n",
    "    G = builder.build()\n",
    "\n",
    "    if not nx.is_connected(G):\n",
    "        components = list(nx.connected_components(G))\n",
    "        if not components:\n",
    "            return None, None\n",
    "        Gsub = G.subgraph(max(components, key=len)).copy()\n",
    "    else:\n",
    "        Gsub = G\n",
    "\n",
    "    Gsub = nx.convert_node_labels_to_integers(Gsub, ordering=\"sorted\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Useful if one wants to ignore angular effects\n",
    "    if USE_ANGLES:\n",
    "        res, degs, dists, pairs, angles = RGGBuilder.sample_commute_times_even_distance_w_angles(\n",
    "            Gsub, nsamples=nsamples, n_bins=20, seed=seed,\n",
    "            min_dist=builder.radius, max_dist=2\n",
    "        )\n",
    "    else:\n",
    "        res, degs, dists, pairs = RGGBuilder.sample_commute_times_even_distance(\n",
    "            Gsub, nsamples=nsamples, n_bins=20, seed=seed,\n",
    "            min_dist=builder.radius, max_dist=2\n",
    "        )\n",
    "\n",
    "    if len(res) < 10:\n",
    "        return None, None\n",
    "\n",
    "    safe_dists = dists.copy()\n",
    "    safe_dists[safe_dists == 0] = 1e-9\n",
    "    current_angles = angles if USE_ANGLES else np.zeros_like(dists)\n",
    "\n",
    "    X = np.column_stack([\n",
    "        dists**2,\n",
    "        np.log(safe_dists),\n",
    "        dists**4 * np.cos(4 * current_angles),\n",
    "        degs,\n",
    "    ])\n",
    "    y = np.array(res)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CORE FUNCTION\n",
    "# ---------------------------\n",
    "def compute_r2(n, k, nsamples=NSAMPLES, base_seed=BASE_SEED):\n",
    "    \"\"\"\n",
    "    Train LASSO on n_train_graphs pooled graphs, test on n_test_graphs pooled graphs.\n",
    "    Returns out-of-sample R². Returns NaN on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- TRAINING: pool data from n_train_graphs graphs ---\n",
    "        X_train_parts, y_train_parts = [], []\n",
    "        for i in range(N_TRAIN_GRAPHS):\n",
    "            X, y = build_features(n, k, nsamples, seed=base_seed + i)\n",
    "            if X is not None:\n",
    "                X_train_parts.append(X)\n",
    "                y_train_parts.append(y)\n",
    "\n",
    "        if len(X_train_parts) == 0:\n",
    "            return np.nan\n",
    "\n",
    "        X_train = np.vstack(X_train_parts)\n",
    "        y_train = np.concatenate(y_train_parts)\n",
    "\n",
    "        # --- FIT LASSO ---\n",
    "        model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            Lasso(alpha=1e-6, random_state=0, max_iter=50000)\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        lasso  = model.named_steps['lasso']\n",
    "        scaler = model.named_steps['standardscaler']\n",
    "        real_coefs     = lasso.coef_ / scaler.scale_\n",
    "        real_intercept = lasso.intercept_ - np.sum(real_coefs * scaler.mean_)\n",
    "\n",
    "        # --- TESTING: pool data from n_test_graphs new graphs ---\n",
    "        X_test_parts, y_test_parts = [], []\n",
    "        for i in range(N_TEST_GRAPHS):\n",
    "            # Use seeds that don't overlap with training seeds\n",
    "            X, y = build_features(n, k, nsamples, seed=base_seed + N_TRAIN_GRAPHS + i)\n",
    "            if X is not None:\n",
    "                X_test_parts.append(X)\n",
    "                y_test_parts.append(y)\n",
    "\n",
    "        if len(X_test_parts) == 0:\n",
    "            return np.nan\n",
    "\n",
    "        X_test = np.vstack(X_test_parts)\n",
    "        y_test = np.concatenate(y_test_parts)\n",
    "\n",
    "        # --- OUT-OF-SAMPLE R² ---\n",
    "        y_pred  = X_test @ real_coefs + real_intercept\n",
    "        ss_res  = np.sum((y_test - y_pred) ** 2)\n",
    "        ss_tot  = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "        r2      = 1 - ss_res / ss_tot\n",
    "\n",
    "        return float(r2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] n={n}, k={k} failed: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# SWEEP OVER GRID\n",
    "# ---------------------------\n",
    "R2_grid = np.full((len(N_VALUES), len(K_VALUES)), np.nan)\n",
    "\n",
    "total = len(N_VALUES) * len(K_VALUES)\n",
    "done  = 0\n",
    "\n",
    "for i, n in enumerate(N_VALUES):\n",
    "    for j, k in enumerate(K_VALUES):\n",
    "        done += 1\n",
    "        print(f\"[{done}/{total}] Running n={n}, k={k} ...\", end=\"  \")\n",
    "        r2 = compute_r2(n, k, nsamples=NSAMPLES, base_seed=BASE_SEED)\n",
    "        R2_grid[i, j] = r2\n",
    "        print(f\"R² = {r2:.4f}\" if not np.isnan(r2) else \"R² = NaN\")\n",
    "\n",
    "# ---------------------------\n",
    "# BUILD DATAFRAME\n",
    "# ---------------------------\n",
    "records = []\n",
    "for i, n in enumerate(N_VALUES):\n",
    "    for j, k in enumerate(K_VALUES):\n",
    "        records.append({\n",
    "            \"n\":         n,\n",
    "            \"k\":         k,\n",
    "            \"ln(n)\":     np.log(n),\n",
    "            \"r2\":        R2_grid[i, j],\n",
    "            \"above_threshold\": k >= np.log(n),   # whether k is above ln(n)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df[\"r2\"] = df[\"r2\"].astype(float)\n",
    "\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "CSV_PATH = \"Assymptotic_Analysis_R2_Results.csv\"\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f\"\\nDataFrame saved to {CSV_PATH}\")\n",
    "\n",
    "# ---------------------------\n",
    "# LINE PLOT  (R² vs k, coloured by n)\n",
    "# ---------------------------\n",
    "\n",
    "# Organise df into dict: r2_dict[n][k] = r2\n",
    "r2_dict = {}\n",
    "for _, row in df.iterrows():\n",
    "    n, k, r2_val = int(row[\"n\"]), row[\"k\"], row[\"r2\"]\n",
    "    if n not in r2_dict:\n",
    "        r2_dict[n] = {}\n",
    "    r2_dict[n][k] = r2_val\n",
    "\n",
    "cmap = plt.cm.plasma\n",
    "norm = plt.Normalize(vmin=np.log2(min(N_VALUES)), vmax=np.log2(max(N_VALUES)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "for n in sorted(r2_dict.keys()):\n",
    "    ks   = sorted(r2_dict[n].keys())\n",
    "    vals = [r2_dict[n][k] for k in ks]\n",
    "    color = cmap(norm(np.log2(n)))\n",
    "\n",
    "    # Separate valid and NaN points so the line isn't broken by NaNs\n",
    "    ks_arr   = np.array(ks, dtype=float)\n",
    "    vals_arr = np.array(vals, dtype=float)\n",
    "    valid    = ~np.isnan(vals_arr)\n",
    "\n",
    "    ax.plot(ks_arr[valid], vals_arr[valid],\n",
    "            marker='o', linewidth=2, markersize=6,\n",
    "            color=color, label=f\"n = {n:,}\")\n",
    "\n",
    "    # Annotate each valid point with its R² value\n",
    "    for k_pt, v_pt in zip(ks_arr[valid], vals_arr[valid]):\n",
    "        ax.annotate(\n",
    "            f\"{v_pt:.3f}\", (k_pt, v_pt),\n",
    "            textcoords=\"offset points\", xytext=(0, 8),\n",
    "            ha='center', fontsize=7, color=color, fontweight='bold'\n",
    "        )\n",
    "\n",
    "    # Mark NaN points with grey X\n",
    "    if np.any(~valid):\n",
    "        ax.scatter(ks_arr[~valid], np.zeros_like(ks_arr[~valid]),\n",
    "                   c='lightgrey', marker='X', s=150,\n",
    "                   edgecolors='k', linewidths=0.6, zorder=3)\n",
    "\n",
    "# Vertical dotted lines at k = ln(n) for each n\n",
    "for n in sorted(r2_dict.keys()):\n",
    "    color = cmap(norm(np.log2(n)))\n",
    "    ax.axvline(np.log(n), color=color, linewidth=0.8, linestyle=':', alpha=0.7)\n",
    "\n",
    "# Colorbar keyed to n\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)\n",
    "cbar.set_label(r\"$\\log_2(n)$\", fontsize=12)\n",
    "cbar.set_ticks([np.log2(n) for n in sorted(r2_dict.keys())])\n",
    "cbar.set_ticklabels([f\"{n:,}\" for n in sorted(r2_dict.keys())])\n",
    "\n",
    "ax.set_xlabel(\"Mean Degree  $k$\", fontsize=13)\n",
    "ax.set_ylabel(\"Out-of-Sample  $R^2$\", fontsize=13)\n",
    "ax.set_title(\n",
    "    f\"LASSO $R^2$ vs Mean Degree across System Sizes\\n\"\n",
    "    f\"(Train: {N_TRAIN_GRAPHS} graphs × {NSAMPLES} pts  |  Test: {N_TEST_GRAPHS} graphs × {NSAMPLES} pts)\",\n",
    "    fontsize=12\n",
    ")\n",
    "ax.set_xticks(K_VALUES)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.axhline(1.0, color='k', linewidth=0.8, linestyle='--', alpha=0.3)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"r2_vs_k.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# DATA OBTAINED FROM PREVIOUS CELLS\n",
    "# ------------------------------------------------------\n",
    "data = [\n",
    "    (512,  5, 0.2108), (512,  6, 0.3565), (512,  7, 0.6125), (512,  8, 0.7051), (512,  9, 0.7830),\n",
    "    (1024, 5, 0.2142), (1024, 6, 0.3649), (1024, 7, 0.5389), (1024, 8, 0.6144), (1024, 9, 0.7130),\n",
    "    (2048, 5, 0.2101), (2048, 6, 0.3681), (2048, 7, 0.5149), (2048, 8, 0.6256), (2048, 9, 0.7141),\n",
    "    (4096, 5, 0.2043), (4096, 6, 0.3880), (4096, 7, 0.5375), (4096, 8, 0.6927), (4096, 9, 0.7730),\n",
    "]\n",
    "\n",
    "n_values = sorted(set(d[0] for d in data))\n",
    "k_values = sorted(set(d[1] for d in data))\n",
    "\n",
    "# Organise into dict: r2[n][k] = r2\n",
    "r2 = {n: {} for n in n_values}\n",
    "for n, k, val in data:\n",
    "    r2[n][k] = val\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# PLOT\n",
    "# ------------------------------------------------------\n",
    "cmap = plt.cm.plasma\n",
    "norm = plt.Normalize(vmin=np.log2(min(n_values)), vmax=np.log2(max(n_values)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "for n in n_values:\n",
    "    ks   = sorted(r2[n].keys())\n",
    "    vals = [r2[n][k] for k in ks]\n",
    "    color = cmap(norm(np.log2(n)))\n",
    "    ax.plot(ks, vals, marker='o', linewidth=2, markersize=6, color=color, label=f\"n = {n:,}\")\n",
    "\n",
    "# Vertical lines at k = ln(n) for each n\n",
    "for n in n_values:\n",
    "    color = cmap(norm(np.log2(n)))\n",
    "    ax.axvline(np.log(n), color=color, linewidth=0.8, linestyle=':', alpha=0.7)\n",
    "\n",
    "# Colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)\n",
    "cbar.set_label(r\"$\\log_2(n)$\", fontsize=12)\n",
    "cbar.set_ticks([np.log2(n) for n in n_values])\n",
    "cbar.set_ticklabels([f\"{n:,}\" for n in n_values])\n",
    "\n",
    "ax.set_xlabel(\"Mean Degree  $k$\", fontsize=13)\n",
    "ax.set_ylabel(\"Out-of-Sample  $R^2$\", fontsize=13)\n",
    "ax.set_title(\"LASSO $R^2$ vs Mean Degree across System Sizes\", fontsize=13)\n",
    "ax.set_xticks(k_values)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(1.0, color='k', linewidth=0.8, linestyle='--', alpha=0.3)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"r2_vs_k.png\", dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
